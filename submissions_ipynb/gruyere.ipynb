{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-04-02T12:52:34.802677Z","iopub.status.busy":"2023-04-02T12:52:34.801966Z","iopub.status.idle":"2023-04-02T12:52:58.777613Z","shell.execute_reply":"2023-04-02T12:52:58.776007Z","shell.execute_reply.started":"2023-04-02T12:52:34.802604Z"},"trusted":true},"outputs":[],"source":["#%pip install -q keras_nlp\n","#%pip install -q tflite_runtime\n","\n","#import gc\n","normalized_length = 10"]},{"cell_type":"markdown","metadata":{},"source":["utils"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-02T12:52:58.781387Z","iopub.status.busy":"2023-04-02T12:52:58.780997Z","iopub.status.idle":"2023-04-02T12:52:58.807082Z","shell.execute_reply":"2023-04-02T12:52:58.805801Z","shell.execute_reply.started":"2023-04-02T12:52:58.781349Z"},"trusted":true},"outputs":[],"source":["import math\n","import time\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import os\n","from os.path import join as pjoin\n","\n","ROWS_PER_FRAME = 543  # number of landmarks per frame\n","\n","def load_relevant_data_subset(pq_path):\n","    data_columns = ['x', 'y', 'z']\n","    data = pd.read_parquet(pq_path, columns=data_columns)\n","    n_frames = int(len(data) / ROWS_PER_FRAME)\n","    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n","    return data.astype(np.float32)\n","\n","def tf_get_features(ftensor):\n","    def feat_wrapper(ftensor):\n","        return load_relevant_data_subset(ftensor.numpy().decode('utf-8'))\n","    return tf.py_function(\n","        feat_wrapper,\n","        [ftensor],\n","        Tout=tf.float32\n","    )\n","\n","def tf_nan_mean(x, axis=0, keepdims=True):\n","    return (tf.reduce_sum(\n","        tf.where(tf.math.is_nan(x), tf.zeros_like(x), x), \n","        axis=axis, keepdims=keepdims) \n","        / tf.reduce_sum(\n","            tf.where(\n","                tf.math.is_nan(x), tf.zeros_like(x), tf.ones_like(x)), \n","            axis=axis, keepdims=keepdims))\n","\n","def tf_nan_std(x, axis=0, keepdims=True):\n","    d = x - tf_nan_mean(x, axis=axis, keepdims=keepdims)\n","    return tf.math.sqrt(tf_nan_mean(d * d, axis=axis, keepdims=keepdims))\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","def timeSpent(since):\n","    now = time.time()\n","    s = now - since\n","    return asMinutes(s)\n","\n","class TimeLimitCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, start_time, max_duration_hours=8, max_duration_minutes=30):\n","        super(TimeLimitCallback, self).__init__()\n","        self.start_time = start_time\n","        self.max_duration_seconds = max_duration_hours * 3600 + max_duration_minutes * 60\n","\n","    def on_train_batch_end(self, batch, logs=None):\n","        elapsed_time = time.time() - self.start_time\n","        if elapsed_time > self.max_duration_seconds:\n","            self.model.stop_training = True\n","            print(f\"Training stopped: time limit of {self.max_duration_seconds/3600:.1f} hours exceeded\")\n","\n","@tf.autograph.experimental.do_not_convert\n","def detuple(v, l, g, pid, sid):\n","    return (v, l)\n","\n","@tf.autograph.experimental.do_not_convert\n","def ensure(shape):\n","    return lambda x : tf.ensure_shape(x, shape)\n","\n","def scheduler(epoch, lr):\n","    if epoch < 8:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","    \n","def create_load_tfrecords(new=False):\n","    idx = 0\n","    while f\"run_{idx}\" in os.listdir('.'):\n","        idx +=1\n","\n","    if new:\n","        path = f\"run_{idx}\"\n","        print(f\"Results will be saved at path {path}\")\n","        os.makedirs(path)\n","        # !mkdir $path\n","\n","    else:\n","        path = f\"run_{idx-1}\"\n","        print(f\"Using path {path}\")\n","    \n","    return pjoin(path, 'full_cv.tfrecord')"]},{"cell_type":"markdown","metadata":{},"source":["Datasets"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-02T12:52:58.809549Z","iopub.status.busy":"2023-04-02T12:52:58.809034Z","iopub.status.idle":"2023-04-02T12:52:59.029185Z","shell.execute_reply":"2023-04-02T12:52:59.028201Z","shell.execute_reply.started":"2023-04-02T12:52:58.809501Z"},"trusted":true},"outputs":[],"source":["from os.path import join as pjoin\n","from os.path import exists\n","import os\n","from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\n","import pandas as pd\n","import tensorflow as tf\n","from tqdm import tqdm\n","import numpy as np\n","import json\n","\n","# from utils import tf_get_features\n","\n","try :\n","    BASE_DIR = \"/kaggle/input/asl-signs/\"\n","    df = pd.read_csv(pjoin(BASE_DIR, \"train.csv\"))\n","except :\n","    BASE_DIR = \"asl-signs\"\n","    df = pd.read_csv(pjoin(BASE_DIR, \"train.csv\"))\n","\n","path2label = dict(zip(df.path, df.sign))\n","label2int = json.load(open(pjoin(BASE_DIR, \"sign_to_prediction_index_map.json\"), 'rb'))\n","\n","# KFold\n","def get_KFold_dataset(preprocessing, shape=(None, 122), path='untitled', n_splits=7):\n","    dir_path = path\n","    path = pjoin(path, 'full_cv.tfrecord')\n","\n","    def parse_function(example_proto):\n","        feature_description = {\n","            # 'vector': tf.io.FixedLenSequenceFeature(shape=(164), dtype=tf.float32, allow_missing=True), #useful when using padded batches\n","            'vector': tf.io.FixedLenFeature(shape=(), dtype=tf.string),\n","            'label': tf.io.FixedLenFeature(shape=(), dtype=tf.int64),\n","            'group': tf.io.FixedLenFeature(shape=(), dtype=tf.int64),\n","            'pid': tf.io.FixedLenFeature(shape=(), dtype=tf.int64),\n","            'sid': tf.io.FixedLenFeature(shape=(), dtype=tf.int64)\n","        }\n","        parsed_example = tf.io.parse_single_example(example_proto, feature_description)\n","        vector = tf.io.parse_tensor(parsed_example['vector'], out_type=tf.float32)\n","        vector = tf.expand_dims(vector, 0)\n","        vector = tf.RaggedTensor.from_tensor(vector, ragged_rank=1)\n","        vector = tf.squeeze(vector, axis=0)\n","        return vector, parsed_example['label'], parsed_example['group'], parsed_example['pid'], parsed_example['sid']\n","\n","    if exists(dir_path):\n","        print(f\"Reloading dataset from path {path}\")\n","    else:\n","        print(f\"Dataset will be saved at path {path}\")\n","        os.makedirs(dir_path)\n","\n","        ds = tf.data.TFRecordDataset(path)\n","        X_ds = tf.data.Dataset.from_tensor_slices(\n","            BASE_DIR + \"/\" + df.path.values\n","            ).map(tf_get_features)\n","        y_ds = tf.data.Dataset.from_tensor_slices(\n","            df.sign.map(label2int).values.reshape(-1,1)\n","            )\n","        \n","        # Perform stratisfied kfold split\n","        sgkf = StratifiedGroupKFold(n_splits=n_splits, random_state=42, shuffle=True)\n","\n","        fold2id = dict()\n","        for fold_idx, (index_train, index_valid) in enumerate(sgkf.split(df.path, df.sign, df.participant_id)):\n","            fold2id[fold_idx] = np.unique(df.participant_id.values[index_valid])\n","            \n","        id2fold = dict()\n","        for k,v in fold2id.items():\n","            for vv in v:\n","                id2fold[vv] = k\n","\n","        g_ds = tf.data.Dataset.from_tensor_slices(\n","            df.participant_id.map(id2fold).values.reshape(-1, 1)\n","        )\n","        pid_ds = tf.data.Dataset.from_tensor_slices(\n","            df.participant_id.values\n","        )\n","        sid_ds = tf.data.Dataset.from_tensor_slices(\n","            df.sequence_id.values\n","        )\n","        \n","        with tf.io.TFRecordWriter(path) as writer:\n","            zipper = zip(X_ds.map(lambda x: tf.ensure_shape(x, (None, 543, 3))).map(preprocessing).map(lambda x: tf.ensure_shape(x, shape)), y_ds, g_ds, pid_ds, sid_ds)\n","            for example in zipper:\n","                X, y, g, pid, sid = example\n","                serialized_X = tf.io.serialize_tensor(X).numpy()\n","                feature = {\n","                    'vector': tf.train.Feature(bytes_list=tf.train.BytesList(value=[serialized_X])),\n","                    'label': tf.train.Feature(int64_list=tf.train.Int64List(value=y.numpy().flatten())),\n","                    'group': tf.train.Feature(int64_list=tf.train.Int64List(value=g.numpy().flatten())),\n","                    'pid': tf.train.Feature(int64_list=tf.train.Int64List(value=pid.numpy().flatten())),\n","                    'sid': tf.train.Feature(int64_list=tf.train.Int64List(value=sid.numpy().flatten())),\n","                }\n","                example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n","                writer.write(example_proto.SerializeToString())\n","\n","    ds = tf.data.TFRecordDataset(path)\n","    ds = ds.map(parse_function).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","    ds = ds.map(\n","        lambda d, l, g, pid, sid: (tf.ensure_shape(d, shape), l, g, pid, sid)\n","        )\n","    \n","    return ds"]},{"cell_type":"markdown","metadata":{},"source":["preprocess_models"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-02T12:52:59.032701Z","iopub.status.busy":"2023-04-02T12:52:59.031875Z","iopub.status.idle":"2023-04-02T12:52:59.057842Z","shell.execute_reply":"2023-04-02T12:52:59.056789Z","shell.execute_reply.started":"2023-04-02T12:52:59.032647Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","tfkl = tf.keras.layers\n","# from utils import *\n","\n","lipsUpperOuter = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291]\n","lipsLowerOuter = [146, 91, 181, 84, 17, 314, 405, 321, 375, 291]\n","lipsUpperInner = [78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308]\n","lipsLowerInner = [78, 95, 88, 178, 87, 14, 317, 402, 318, 324, 308]\n","lips_idx = list(set(lipsUpperOuter + lipsLowerOuter + lipsUpperInner + lipsLowerInner))\n","lips_idx = tf.constant(lips_idx, dtype=tf.int32)\n","\n","# Rq: possible d'avoir des timesteps hand incomplets ? Avec par exemple quelques landmarks de hand NaN sur ce timestep ? -> nanmean\n","\n","class Preprocess(tf.keras.layers.Layer):\n","    def __init__(self, normalized_length):\n","        super(Preprocess, self).__init__()\n","        self.normalized_length = normalized_length\n","\n","    def call(self, frames):\n","        frames = frames[:, :, :2] #drop z axis\n","\n","        # Hands\n","        lh_frames, rh_frames = frames[:, 468:489], frames[:, 522:]\n","\n","        lh_frames_x, lh_frames_y = lh_frames[:, :, 0], lh_frames[:, :, 1]\n","        rh_frames_x, rh_frames_y = rh_frames[:, :, 0], rh_frames[:, :, 1]\n","        lh_frames, rh_frames = tf.stack([lh_frames_x, 1-lh_frames_y], axis=-1), tf.stack([1-rh_frames_x, 1-rh_frames_y], axis=-1)\n","\n","        hand = tf.stack([lh_frames, rh_frames], axis=0)\n","        hand = tf.where(tf.math.is_nan(hand), tf.zeros_like(tf.math.is_nan(hand), dtype=tf.float32), hand)\n","        hand = tf.reduce_sum(hand, axis=0)\n","\n","        handsNanMask = tf.cast(tf.reduce_sum(hand, axis=[1, 2]), tf.bool) ## drops timestep having no hand data\n","        hand = tf.boolean_mask(hand, handsNanMask, axis=0)\n","\n","        # Pose\n","        # pose = frames[:, 489:522]\n","\n","        # Lips\n","        lips = tf.gather(frames, lips_idx, axis=1)\n","        lips = tf.boolean_mask(lips, handsNanMask, axis=0)\n","        lips = tf.where(tf.math.is_nan(lips), tf_nan_mean(lips), lips)\n","        lips = tf.where(tf.math.is_nan(lips), tf.zeros_like(lips), lips)\n","\n","        # return tfkl.Flatten()(tf.concat([hand, lips], axis=1))\n","\n","        # Time reduction ?\n","        raw_data = tf.concat([hand, lips], axis=1)\n","        source_length = tf.shape(raw_data)[0]\n","        normalized_idx = tf.linspace(0.0, tf.cast(source_length-1, tf.float32), self.normalized_length+1)\n","        # normalized_idx = tf.cast(tf.round(normalized_idx, tf.int32), tf.int32)\n","        normalized_idx = tf.cast(normalized_idx, tf.int32)\n","\n","        sampled = list()\n","        for idx in range(self.normalized_length):\n","            start, end = normalized_idx[idx], normalized_idx[idx+1]\n","            # end = end + tf.cast(tf.equal(start, end), tf.int32) # avoid null length\n","            sample = raw_data[start:end]\n","            # sample = tf.concat([tf_nan_mean(sample), tf_nan_std(sample)], axis=1) #changer ordre ici\n","            sample = tf_nan_mean(sample)\n","            sampled.append(sample)\n","        sampled = tf.concat(sampled, axis=0)\n","\n","        #tmp\n","        sampled = tfkl.Flatten()(sampled)\n","\n","        sampled = tf.where(tf.math.is_nan(sampled), tf.zeros_like(tf.math.is_nan(sampled), dtype=tf.float32), sampled)\n","        sampledNanMask = tf.cast(tf.reduce_sum(sampled, axis=1), tf.bool)\n","        sampled = tf.boolean_mask(sampled, sampledNanMask, axis=0)\n","        return sampled"]},{"cell_type":"markdown","metadata":{},"source":["models"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-02T12:52:59.062142Z","iopub.status.busy":"2023-04-02T12:52:59.061263Z","iopub.status.idle":"2023-04-02T12:52:59.074872Z","shell.execute_reply":"2023-04-02T12:52:59.073424Z","shell.execute_reply.started":"2023-04-02T12:52:59.062096Z"},"trusted":true},"outputs":[],"source":["from keras_nlp.layers.transformer_encoder import TransformerEncoder\n","# from keras_nlp.layers import SinePositionEncoding\n","import tensorflow as tf\n","tfkl = tf.keras.layers\n","\n","def get_model(\n","        hp, \n","        input_shape=(10, (2*(21 + 40)))\n","        ):\n","    \n","    inputs = tf.keras.Input(input_shape, dtype=tf.float32)\n","    \n","    vector = tfkl.Bidirectional(tfkl.GRU(hp['gru1'], return_sequences=True))(inputs) #hp['gru1']=96 first test\n","    vector = tfkl.BatchNormalization()(vector)\n","    vector = tfkl.Activation('gelu')(vector)\n","    \n","    for _ in range(1):\n","        vector = TransformerEncoder(intermediate_dim=hp['ff_dim'], num_heads=hp['nhead'], dropout=hp['input_dropout'])(vector) #hp['input_dropout']=0.3 first test\n","        #hp['nhead']=12, hp['ff_dim']=160\n","    vector = tfkl.Bidirectional(tfkl.GRU(hp['gru2']))(vector) #hp['gru2']=96 first test\n","    vector = tfkl.Dropout(hp['output_dropout'])(vector) #hp['output_dropout']=0.2 first test\n","\n","    output = tfkl.Dense(250, activation=\"softmax\")(vector)\n","    model = tf.keras.Model(inputs=inputs, outputs=output)\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["rest"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-04-02T12:52:59.077964Z","iopub.status.busy":"2023-04-02T12:52:59.077004Z","iopub.status.idle":"2023-04-02T12:53:00.407269Z","shell.execute_reply":"2023-04-02T12:53:00.405568Z","shell.execute_reply.started":"2023-04-02T12:52:59.077908Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset will be saved at path preprocessed_datasets/testkaggle/full_cv.tfrecord\n","WARNING:tensorflow:From /Users/gus/Desktop/envs/asl/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n","Instructions for updating:\n","Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n","WARNING:tensorflow:AutoGraph could not transform <function get_KFold_dataset.<locals>.<lambda> at 0x103c141f0> and will run it as-is.\n","Cause: could not parse the source code of <function get_KFold_dataset.<locals>.<lambda> at 0x103c141f0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n","Match 0:\n","lambda x: tf.ensure_shape(x, shape)\n","\n","Match 1:\n","lambda x: tf.ensure_shape(x, (None, 543, 3))\n","\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function get_KFold_dataset.<locals>.<lambda> at 0x103c141f0> and will run it as-is.\n","Cause: could not parse the source code of <function get_KFold_dataset.<locals>.<lambda> at 0x103c141f0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n","Match 0:\n","lambda x: tf.ensure_shape(x, shape)\n","\n","Match 1:\n","lambda x: tf.ensure_shape(x, (None, 543, 3))\n","\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function get_KFold_dataset.<locals>.<lambda> at 0x166254550> and will run it as-is.\n","Cause: could not parse the source code of <function get_KFold_dataset.<locals>.<lambda> at 0x166254550>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n","Match 0:\n","lambda x: tf.ensure_shape(x, shape)\n","\n","Match 1:\n","lambda x: tf.ensure_shape(x, (None, 543, 3))\n","\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function get_KFold_dataset.<locals>.<lambda> at 0x166254550> and will run it as-is.\n","Cause: could not parse the source code of <function get_KFold_dataset.<locals>.<lambda> at 0x166254550>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n","Match 0:\n","lambda x: tf.ensure_shape(x, shape)\n","\n","Match 1:\n","lambda x: tf.ensure_shape(x, (None, 543, 3))\n","\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"name":"stderr","output_type":"stream","text":["2023-04-02 16:01:54.660810: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 10, 122)]         0         \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 10, 160)          97920     \n"," l)                                                              \n","                                                                 \n"," batch_normalization (BatchN  (None, 10, 160)          640       \n"," ormalization)                                                   \n","                                                                 \n"," activation (Activation)     (None, 10, 160)           0         \n","                                                                 \n"," transformer_encoder (Transf  (None, 10, 160)          165472    \n"," ormerEncoder)                                                   \n","                                                                 \n"," bidirectional_1 (Bidirectio  (None, 256)              222720    \n"," nal)                                                            \n","                                                                 \n"," dropout (Dropout)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 250)               64250     \n","                                                                 \n","=================================================================\n","Total params: 551,002\n","Trainable params: 550,682\n","Non-trainable params: 320\n","_________________________________________________________________\n"]}],"source":["folds = 3\n","path = \"preprocessed_datasets/testkaggle/\"\n","\n","ds = get_KFold_dataset(Preprocess(normalized_length), (None, 122), path, folds) #tmp\n","hp = {\n","    \"gru1\": 80,\n","    'nhead': 16,\n","    'ff_dim': 192,\n","    'input_dropout': 0.2,\n","    'gru2': 128,\n","    'output_dropout': 0.3\n","}\n","\n","get_model(hp).summary()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-02T12:53:00.410414Z","iopub.status.busy":"2023-04-02T12:53:00.409860Z","iopub.status.idle":"2023-04-02T12:53:00.420089Z","shell.execute_reply":"2023-04-02T12:53:00.418510Z","shell.execute_reply.started":"2023-04-02T12:53:00.410341Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","            *** Fold 0 ***\n","\n","Epoch 1/100\n","3899/3899 [==============================] - 81s 20ms/step - loss: 3.6464 - sparse_categorical_accuracy: 0.2003 - val_loss: 4.1725 - val_sparse_categorical_accuracy: 0.1559 - lr: 0.0010\n","Epoch 2/100\n"," 388/3899 [=>............................] - ETA: 55s - loss: 2.7203 - sparse_categorical_accuracy: 0.3487"]}],"source":["from tqdm.keras import TqdmCallback\n","\n","val_accs = list()  \n","for fold_idx in range(folds):\n","    start = time.time()\n","    print(f'\\n            *** Fold {fold_idx} ***\\n')\n","    train_ds = ds.filter(lambda v, l, g, pid, sid: g != fold_idx).map(detuple).padded_batch(16)\n","    valid_ds = ds.filter(lambda v, l, g, pid, sid: g == fold_idx).map(detuple).padded_batch(16)\n","    model = get_model(hp)\n","\n","    lr = 1e-3\n","\n","    model.compile(\n","        tf.keras.optimizers.Adam(learning_rate=lr),\n","        tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n","        metrics=[\n","            tf.keras.metrics.SparseCategoricalAccuracy(),\n","        ]\n","    )\n","    \n","    hist = model.fit(\n","        x=train_ds,\n","        epochs=100,\n","        verbose=1,\n","       callbacks=[\n","            #TqdmCallback(verbose=0),\n","            #TimeLimitCallback(start, 1, 10),\n","            TimeLimitCallback(start, 2, 30),\n","            tf.keras.callbacks.LearningRateScheduler(scheduler),\n","            tf.keras.callbacks.ModelCheckpoint(pjoin(path.split('/')[0], f\"model_{fold_idx}\"), \n","                save_best_only=True, \n","                save_weights_only=True,\n","                restore_best_weights=True, \n","                monitor=\"val_sparse_categorical_accuracy\", mode=\"max\"),\n","            tf.keras.callbacks.EarlyStopping(patience=10, monitor=\"val_sparse_categorical_accuracy\", mode=\"max\", restore_best_weights=True)\n","            ],\n","        validation_data=valid_ds,\n","        validation_freq=1,\n","        workers=2,\n","        use_multiprocessing=True\n","    )\n","\n","    best_acc = max(hist.history['val_sparse_categorical_accuracy'])\n","    print(\"Best acc fold\", fold_idx, \":\\n ->\", 100*round(best_acc, 4), \"%\")\n","    val_accs.append(\n","        best_acc\n","    )\n","    # break\n","\n","print(\"Bagged final valid acc score:\")\n","bagged_score = 100*np.round(np.array(val_accs).mean(), 4)\n","print(bagged_score, \"%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-02T12:53:00.423418Z","iopub.status.busy":"2023-04-02T12:53:00.422876Z","iopub.status.idle":"2023-04-02T12:53:02.500549Z","shell.execute_reply":"2023-04-02T12:53:02.498975Z","shell.execute_reply.started":"2023-04-02T12:53:00.423348Z"},"trusted":true},"outputs":[],"source":["del df\n","#del train_ds\n","#del valid_ds\n","#del ds\n","#del model\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-02T13:33:53.450970Z","iopub.status.busy":"2023-04-02T13:33:53.450462Z","iopub.status.idle":"2023-04-02T13:34:02.093758Z","shell.execute_reply":"2023-04-02T13:34:02.091968Z","shell.execute_reply.started":"2023-04-02T13:33:53.450929Z"},"trusted":true},"outputs":[],"source":["def get_inference_model():\n","    inputs = tf.keras.Input((543, 3), dtype=tf.float32, name=\"inputs\")\n","    \n","    frames = inputs[:, :, :2] #drop z axis\n","\n","    # Hands\n","    lh_frames, rh_frames = frames[:, 468:489], frames[:, 522:]\n","\n","    lh_frames_x, lh_frames_y = lh_frames[:, :, 0], lh_frames[:, :, 1]\n","    rh_frames_x, rh_frames_y = rh_frames[:, :, 0], rh_frames[:, :, 1]\n","    lh_frames, rh_frames = tf.stack([lh_frames_x, 1-lh_frames_y], axis=-1), tf.stack([1-rh_frames_x, 1-rh_frames_y], axis=-1)\n","\n","    hand = tf.stack([lh_frames, rh_frames], axis=0)\n","    hand = tf.where(tf.math.is_nan(hand), tf.zeros_like(tf.math.is_nan(hand), dtype=tf.float32), hand)\n","    hand = tf.reduce_sum(hand, axis=0)\n","\n","    handsNanMask = tf.cast(tf.reduce_sum(hand, axis=[1, 2]), tf.bool) ## drops timestep having no hand data\n","    hand = tf.boolean_mask(hand, handsNanMask, axis=0)\n","\n","    # Pose\n","    # pose = frames[:, 489:522]\n","\n","    # Lips\n","    lips = tf.gather(frames, lips_idx, axis=1)\n","    lips = tf.boolean_mask(lips, handsNanMask, axis=0)\n","    lips = tf.where(tf.math.is_nan(lips), tf_nan_mean(lips), lips)\n","    lips = tf.where(tf.math.is_nan(lips), tf.zeros_like(lips), lips)\n","\n","    # return tfkl.Flatten()(tf.concat([hand, lips], axis=1))\n","\n","    # Time reduction ?\n","    raw_data = tf.concat([hand, lips], axis=1)\n","    source_length = tf.shape(raw_data)[0]\n","    normalized_idx = tf.linspace(0.0, tf.cast(source_length-1, tf.float32), normalized_length+1)\n","    # normalized_idx = tf.cast(tf.round(normalized_idx, tf.int32), tf.int32)\n","    normalized_idx = tf.cast(normalized_idx, tf.int32)\n","\n","    sampled = list()\n","    for e,idx in enumerate(range(normalized_length)):\n","        start, end = normalized_idx[idx], normalized_idx[idx+1]\n","        if e==0:\n","            end = end + tf.cast(tf.equal(start, end), tf.int32) # avoid null length\n","        sample = raw_data[start:end]\n","        # sample = tf.concat([tf_nan_mean(sample), tf_nan_std(sample)], axis=1) #changer ordre ici\n","        sample = tf_nan_mean(sample)\n","        sampled.append(sample)\n","    sampled = tf.concat(sampled, axis=0)\n","\n","    #tmp\n","    sampled = tfkl.Flatten()(sampled)\n","\n","    sampled = tf.where(tf.math.is_nan(sampled), tf.zeros_like(tf.math.is_nan(sampled), dtype=tf.float32), sampled)\n","    sampledNanMask = tf.cast(tf.reduce_sum(sampled, axis=1), tf.bool)\n","    sampled = tf.boolean_mask(sampled, sampledNanMask, axis=0)\n","    \n","    pad_length = 10 - tf.shape(sampled)[0]\n","    zero = tf.zeros_like(sampled[:1])\n","    pad = tf.repeat(zero, pad_length, axis=0)\n","    sampled = tf.concat([sampled, pad], axis=0)\n","    \n","    diffs = tf.expand_dims(sampled, 0)\n","    #diffs = next(iter(tf.data.Dataset.from_tensor_slices(diffs).padded_batch(1, (10, 122))))\n","\n","    models = [get_model(hp) for _ in range(folds)]\n","    #for fold_idx in range(folds):\n","    #    models[fold_idx].load_weights(pjoin(path.split('/')[0], f\"model_{fold_idx}\"))\n","    outputs = [model(diffs) for model in models]\n","    vector = tf.reduce_mean(outputs, axis=0) #average the models\n","\n","    output = tfkl.Activation(activation=\"linear\", name=\"outputs\")(vector)\n","    inference_model = tf.keras.Model(inputs=inputs, outputs=output) \n","    inference_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n","    return inference_model\n","\n","inference_model = get_inference_model()\n","#inference_model.summary()\n","params = inference_model.count_params()\n","print(params/1e6)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-02T13:34:02.097289Z","iopub.status.busy":"2023-04-02T13:34:02.096760Z","iopub.status.idle":"2023-04-02T13:37:54.048340Z","shell.execute_reply":"2023-04-02T13:37:54.046814Z","shell.execute_reply.started":"2023-04-02T13:34:02.097247Z"},"trusted":true},"outputs":[],"source":["converter = tf.lite.TFLiteConverter.from_keras_model(inference_model)\n","tflite_model = converter.convert()\n","model_path = \"model.tflite\"\n","# Save the model.\n","with open(model_path, 'wb') as f:\n","    f.write(tflite_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-02T13:37:58.527490Z","iopub.status.busy":"2023-04-02T13:37:58.526972Z","iopub.status.idle":"2023-04-02T13:38:00.247500Z","shell.execute_reply":"2023-04-02T13:38:00.246298Z","shell.execute_reply.started":"2023-04-02T13:37:58.527442Z"},"trusted":true},"outputs":[],"source":["!zip submission.zip $model_path"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-02T13:38:47.523392Z","iopub.status.busy":"2023-04-02T13:38:47.522904Z","iopub.status.idle":"2023-04-02T13:38:48.481474Z","shell.execute_reply":"2023-04-02T13:38:48.479843Z","shell.execute_reply.started":"2023-04-02T13:38:47.523348Z"},"trusted":true},"outputs":[],"source":["BASE_DIR = \"/kaggle/input/asl-signs/\"\n","train_df = pd.read_csv(pjoin(BASE_DIR, \"train.csv\"))\n","\n","path2label = dict(zip(train_df.path, train_df.sign))\n","label2int = json.load(open(pjoin(BASE_DIR, \"sign_to_prediction_index_map.json\"), 'rb'))\n","\n","int2label = {v:k for k,v in label2int.items()}\n","\n","import tflite_runtime.interpreter as tflite\n","interpreter = tflite.Interpreter(model_path)\n","found_signatures = list(interpreter.get_signature_list().keys())\n","prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n","#for i in range(len(train_df)):\n","for i in range(50):\n","    frames = load_relevant_data_subset(f'/kaggle/input/asl-signs/{train_df.iloc[i].path}')\n","    output = prediction_fn(inputs=frames)\n","    sign = np.argmax(output[\"outputs\"])\n","    print(f\"Predicted label: {int2label[sign]}, Actual Label: {train_df.iloc[i].sign} (shape {frames.shape})\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
